\documentclass[main.tex]{subfiles}
\begin{document}
\section{Introduction}

\subsection{Dead Reckoning}
% explain the issues of dead Reckoning
% use as an introduction: 
% 	to the FWKin prob.
% 	to the different sensors used

%todo: fix 1st sent.

Robot localization is crucial to effective robot locomotion. Various methods are
used to determine the current and future locations of robot; each unique to the
available sensors, robot structure and environment. Dead reckoning is one of the
simpler methods used. It requires as few sensors as possible and relies mostly
on known motion models and states.  Dead reckoning is a method of finding the
location of an object based on a known motion model and current state
information. Once the current state of an object is known then its motion model
can be used to predict future motion states. For example, one can predict the
future position of a robot if it is known that that the robot is moving in a
straight line and at a constant speed and its current position.

A two wheeled robot as shown in \figref{2wheelBot} will be used for our analysis
of dead reckoning. Two wheeled odometry is used to create a motion model of the
robot which is then used to predict future locations of the robot. In this study
only the $x$ and $y$ coordinates are of interest although velocity can easily
derived. 

\begin{figure}[H]
\begin{center}
\include{2wheelBot}
\end{center}
\caption{2 Wheeled Robot (Side view)}
\label{fig:2wheelBot}
\end{figure}

We will begin our analysis with the odometry model of the two wheeled robot. The
odometry model is as follows (its derivation is beyond the scope of this
report):

\begin{equation}
\label{eq:deadReckonState}
	P(t) = 
	\begin{bmatrix}
	S \\ \theta
	\end{bmatrix}
	=
	\begin{bmatrix}
	\frac{1}{2}	& \frac{1}{2} \\[0.3em]
	\frac{1}{\mathrm{w}} & -\frac{1}{\mathrm{w}}
	\end{bmatrix} 
	\begin{bmatrix}
	s_R(t) \\ s_L(t)
	\end{bmatrix}
\end{equation}

Where $S$ and $\theta$ respectively are the robot distance travelled and heading
of the robot. $s_L$ and $s_R$ are the distances traveled by each wheel (left and
right respectively). $w$ is the distance between the contact points of the
wheels of the robot.

\begin{figure}[H]
	\begin{center}
	\input{2wheelMotion}
	\end{center}
	\caption{Robot Motion Model from $t=0 -$ \delt}
	\label{fig:2wrMotion}
\end{figure}


From \eqref{deadReckonState} we can create a motion model relative to the
inertial frame of reference $I$ (as shown in \figref{2wrMotion}). To simplify
our analysis the following is assumed:

\begin{itemize}
\item The robot's motion model is measured on a time differential \delt that
is small with respect to the total time ($T$) the robot performs its motion. 
\item The robot's wheel encoders are error-less and no wheel slipping occurs.
\item \delt is chosen to be small enough so that $S\mathrm{'}-S \approx 0$ and
thus $S\mathrm{'} = S$.
\end{itemize}

From these assumptions we have a motion model for the robot:

\begin{equation}
\label{eq:motionState}
\xi_{i} = 
\begin{bmatrix}
x \\ y \\ \theta
\end{bmatrix}
=
\begin{bmatrix}
\cos{\theta} & 0\\
\sin{\theta} & 0\\
0 & 1
\end{bmatrix}
P(t_i+\Delta\mathrm{t})-P(t_i)
\end{equation}

$\xi_{i}$ is the position of the robot after some time lapse \delt. Thus to get
the current position of the robot after some time $T$ simply sum the interval
position changes\footnote{A continuous form of \eqref{sumE} is beyond ths scope
of this lab and is not needed computationally.}: 

\begin{equation}
\label{eq:sumE}
\xi(T) = \xi_0 + \sum^{n}_{i=0} \xi_{i} : n = \frac{T}{\Delta\mathrm{t}}
\end{equation}

\eqref{sumE} simply means that given the robots initial position ($\xi_0$) and a sequence
of wheel distance measurements for $t=\{\delT,2\delT,\cdots,T\}$ the position of
the robot at $T$ can be predicted. This of course is only valid for the above
assumptions.

Dead reckoning is not practical when used alone. Sensor noise, wheel slippage,
and distance estimation error ($S-S\mathrm{'}$) all affect the outcome of
\eqref{sumE}. However dead reckoning is not completely useless. In fact it forms
the base motion model for other filter and motion estimation algorithms (such as
the Kalman filter\footnote{\url{https://en.wikipedia.org/wiki/Kalman_filter}}).

%TODO: add section on inertial to robot frame of reference rotation matrix

\subsection{Wheel Encoders}
% usages simple design of quad Encoders sensor readings format (grayscale
% encoding) measuring x/v/a from encoders sources of error

As seen in \eqref{deadReckonState} the robot's motion model is dependent on
wheel distance travelled. Sensors that can translate rotational wheel motion to
linear distance traveled are called wheel encoders. Different types of encoders
are available each with their advantages and disadvantages. In this study we
will examine a quadrature wheel encoder. 

A quadrature encoder uses a disk (as shown in \figref{quadEncode}) and two
optical sensors to track the position of a wheel. The disk is patterned with
alternating dark and light wedges which the optical sensors use to determine the
position of the disk. The encoder is attached concentrically to the axis of the
wheel so that the disk spins at the same angular velocity as the wheel.

\begin{figure}[H]
	\begin{center}
	\include{quadEncode}
	\end{center}
	\caption{Quadrature Encoder}
	\label{fig:quadEncode}
\end{figure}

When light is reflected off of the disk it is detected by the optical sensors
which produce a binary signal depending on the color (typically a white wedge
produces a logical 1 and black a logical 0). Because to sensors are used the
encoder produces two signals; one point A and one for point B. The A and B are
placed such that their output waves have a $90\deg$ phase shift.

\subsection{Sonar Range Finder}
% usages
% simple design explanation (signal threshold and time of flight)
% error types 

\end{document}
